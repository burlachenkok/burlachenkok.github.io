---
layout: post
title: BurTorch (Backpropagation Ultrafast Runtime)
published: true
---

The new paper [BurTorch: Revisiting Training from First Principles by Coupling Autodiff, Math Optimization, and Systems](https://arxiv.org/abs/2503.13795) presents the design choices behind one of the fastest and memory-efficient backpropagation implementations on CPU.

---

<center>
<img height="128px" src="https://burlachenkok.github.io/images/burtorch-logo-2.png"/>
</center>

# Results

The new paper by [Konstantin Burlachenko](https://burlachenkok.github.io/) and [Peter Richt√°rik](https://richtarik.org/), present [BurTorch](https://arxiv.org/abs/2503.13795) and compares it with industry best-practice solutions for automatic differentiation in Machine Learning, considering various operation modes, programming language APIs, and usage across multiple desktop operating systems.

The list of frameworks includes the following:

* **PyTorch**: [https://pytorch.org/](https://pytorch.org/)
* **JAX**: [https://docs.jax.dev/en/latest/](https://docs.jax.dev/en/latest/)
* **TensorFlow**: [https://www.tensorflow.org/](https://www.tensorflow.org/)
* **TensorFlow Lite**: [https://ai.google.dev/edge/litert](https://ai.google.dev/edge/litert)
* **Autograd**: [https://github.com/HIPS/autograd](https://github.com/HIPS/autograd)
* **Micrograd**: [https://x.com/karpathy/status/1803963383018066272](https://x.com/karpathy/status/1803963383018066272)
* **Apple MLX**: [https://github.com/ml-explore/mlx](https://github.com/ml-explore/mlx)

Experiments were conducted on physically distinct computational devices and across major desktop operating systems:

* [macOS Sonoma 14.5](https://developer.apple.com/documentation/macos-release-notes/macos-14_5-release-notes)
* [Ubuntu 20.04.6 LTS](https://releases.ubuntu.com/focal/)
* [Microsoft Windows 11 Home](https://www.microsoft.com/en-us/d/windows-11-home/dg7gmgf0krt0)

For small compute graphs, BurTorch outperforms best-practice solutions by up to **x2000** in runtime and reduces memory consumption by up to **x3500**. 

For a miniaturized [GPT-3 model (Brown et al., 2020)](https://arxiv.org/abs/2005.14165), BurTorch achieves up to a **x20** speedup and reduces memory up to **x80** compared to [PyTorch](https://proceedings.neurips.cc/paper/2019/hash/bdbca288fee7f92f2bfa9f7012727740-Abstract.html) on CPU.

----

# Extra Links

- **The arXiv preprint**: [https://arxiv.org/abs/2503.13795](https://arxiv.org/abs/2503.13795)
- **Podcast** generated via [NotebookLM](https://notebooklm.google/) in an entertaining format:
    - (i) online: [https://www.podbean.com/eas/pb-en4mf-184b9bf](https://www.podbean.com/eas/pb-en4mf-184b9bf)
    - (ii) offline: [https://burlachenkok.github.io/podcasts/burtorch-generated-interview.mp3](https://burlachenkok.github.io/podcasts/burtorch-generated-interview.mp3)
- **The Twitter post**: [https://x.com/burlachekok/status/1902295533139755122](https://x.com/burlachekok/status/1902295533139755122)
- **The LinkedIn post**: [https://www.linkedin.com/posts/burlachenkok_burtorch-backpropagation-ultrafast-runtime-activity-7308035001575505920-w0lB](https://www.linkedin.com/posts/burlachenkok_burtorch-backpropagation-ultrafast-runtime-activity-7308035001575505920-w0lB)

---

# Abstract

In this work, we introduce BurTorch, a compact high-performance framework designed to optimize Deep Learning (DL) training on single-node workstations 
through an exceptionally efficient CPU-based backpropagation ([Rumelhart et al., 1986](https://www.nature.com/articles/323533a0); [Linnainmaa, 1970](https://scholar.googleusercontent.com/scholar.bib?q=info:wRjDZKQ_NKYJ:scholar.google.com/&output=citation&scisdr=ClHdwmNeENKs6Xb1i_s:AFWwaeYAAAAAZ87zk_vuPijL7H0txyMVOwPA1wQ&scisig=AFWwaeYAAAAAZ87zk4D5Rjhb-wNl_c2IxQBTkcc&scisf=4&ct=citation&cd=-1&hl=ru)) implementation. Although modern DL frameworks rely on compiler-like optimizations internally, BurTorch takes a different path. It adopts a minimalist design and demonstrates that, 
in these circumstances, classical compiled programming languages can play a significant role in DL research. 
By eliminating the overhead of large frameworks and making efficient implementation choices, BurTorch achieves orders-of-magnitude improvements in performance and memory efficiency when 
computing the gradient of a function on a CPU. BurTorch features a compact codebase designed to achieve two key goals simultaneously. 
First, it provides a user experience similar to script-based programming environments. 
Second, it dramatically minimizes runtime overheads. In large DL frameworks, the primary source of memory overhead for relatively small computation graphs is due to feature-heavy implementations. 
We benchmarked BurTorch against widely used DL frameworks in their execution modes: 
[JAX (Bradbury et al., 2018)](https://github.com/jax-ml/jax), [PyTorch (Paszke et al., 2019)](https://proceedings.neurips.cc/paper/2019/hash/bdbca288fee7f92f2bfa9f7012727740-Abstract.html), [TensorFlow (Abadi et al., 2016)](https://arxiv.org/abs/1605.08695);
and several standalone libraries: [Autograd (Maclaurin et al., 2015)](https://github.com/HIPS/autograd), [Micrograd (Karpathy, 2020)](https://github.com/karpathy/micrograd), [Apple MLX (Hannun et al., 2023)](https://github.com/ml-explore).
For small compute graphs, BurTorch outperforms best-practice solutions by up to x2000 in runtime and reduces memory consumption by up to x3500. For a miniaturized [GPT-3 model (Brown et al., 2020)](https://arxiv.org/abs/2005.14165), 
BurTorch achieves up to a x20 speedup and reduces memory up to x80 compared to [PyTorch](https://proceedings.neurips.cc/paper/2019/hash/bdbca288fee7f92f2bfa9f7012727740-Abstract.html).

---

# Source Code

BurTorch offers exceptionally low latency and a minimal memory footprint for gradient computation, making it highly advantageous for real-time applications that can positively impact society. However, like many powerful technologies, there is a risk of misuse if it falls into the wrong hands. The authors must carefully consider the most responsible way to distribute the code.

---

<center>
<table style="text-align:center;">
<tr>
<td style="padding:30px;text-align:center;vertical-align:middle;"> <img height="115px" src="https://burlachenkok.github.io/materials/KAUST-logo.svg"/> </td>
</tr>
</table>
</center>
