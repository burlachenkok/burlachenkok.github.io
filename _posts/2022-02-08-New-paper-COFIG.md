---
layout: post
title: Faster rates for compressed federated learning with client-variance reduction
published: true
---

The new paper ["Faster rates for compressed federated learning with client-variance reduction"](https://arxiv.org/abs/2112.13097) has been out.

---

Our paper ["Faster rates for compressed federated learning with client-variance reduction"](https://arxiv.org/abs/2112.13097) has been out.


I was glad to work with [Haoyu Zhao](https://hyzhao.me/) from Princeton University and [Zhize Li](https://zhizeli.github.io/), prof. [Peter Richtarik](https://richtarik.org/) from King Abdullah University of Science and Technology.

We provide rigorous theory and practical experiments. In terms of the last aspect, we are providing comparisons of several state-of-the-art optimization FL methods in empirical and theoretical non-convex settings. Our [COFIG](https://arxiv.org/abs/2112.13097) algorithm has demonstrated in honest comparison excellent results.

The experimental part for that paper has been done in an advanced research simulator for Federated Learning called [FL_PyTorch](https://dl.acm.org/doi/10.1145/3488659.3493775)
